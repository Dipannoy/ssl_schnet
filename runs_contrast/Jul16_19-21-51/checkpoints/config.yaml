batch_size: 128
epochs: 30
eval_every_n_epochs: 1
fine_tune_from: None
log_every_n_steps: 50
gpu: cuda:0

optim:
  optimizer: Adam
  lr: 0.0005
  weight_decay: 1e-6

model: 
  atom_fea_len: 64
  h_fea_len: 64
  n_conv: 3
  n_h: 1

dataset:
  root_dir: zach_222k_bvm_cifs
  max_num_nbr: 12
  radius: 8
  dmin: 0
  step: 0.2
  random_seed: 337

dataloader:
  val_ratio: 0.15
  num_workers: 0

loss:
  embed_size: 64
  lambd: 0.0051
  batch_size: 64
